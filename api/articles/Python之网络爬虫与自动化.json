{"title":"Python之网络爬虫与自动化","uid":"d2c6d2646ec298cd40f48630ec04271a","slug":"Python之网络爬虫与自动化","date":"2020-03-26T01:55:21.000Z","updated":"2021-01-21T02:34:46.000Z","comments":true,"path":"api/articles/Python之网络爬虫与自动化.json","keywords":"A1andNS","cover":"https://cdn.jsdelivr.net/gh/A1andNS/picgo/img/20200323233608.png","content":"<p>今天来学习一下Python语言如何进行网络爬虫和自动化。</p>\n<p>Python语言提供了很多可供使用的第三方库，包括<code>urllib</code>、<code>urllib2</code>、<code>urllib3</code>、<code>wget</code>、<code>scrapy</code>、<code>requests</code>等。这些库都会是好帮手。最经常看到的就是<code>requests</code>库了。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong>网络爬虫</strong>应用一般分为两个步骤：</p>\n<ol>\n<li>通过网络链接获取网页内容</li>\n<li>对获得的网页内容进行处理</li>\n</ol></blockquote>\n<p>说到爬虫还有一个<code>Robots</code>排除协议，也就是爬虫协议，它是网站管理员表达是否希望爬虫自动获取网络信息意愿的方法。管理者一般都会在网站根目录下放置一个<code>robots.txt</code> 文件，并在里面列出哪些链接不允许爬虫爬取。在CTF的WEB解题中也经常会用到<code>robots.txt</code>文件，比如查看一些目录。</p>\n<h2 id=\"requests库的使用\"><a href=\"#requests库的使用\" class=\"headerlink\" title=\"requests库的使用\"></a>requests库的使用</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><code>request</code>库是一个简洁且简单的处理HTTP请求的第三方库</p></blockquote>\n<h3 id=\"requests库简介\"><a href=\"#requests库简介\" class=\"headerlink\" title=\"requests库简介\"></a>requests库简介</h3><p><code>request</code>库是一个简洁且简单的处理HTTP请求的第三方库，最大优点就是程序编写过程接近正常的URL访问过程。这个库是建立在Python语言的<code>urllib3</code>库的基础上，这可能也是Python的特色，在第三方库基础上开发更友好的库，一切都得益于开源。</p>\n<p><code>requests</code>库支持很多丰富的链接访问功能，包括国际域名和URL获取、HTTP长连接和链接缓存、HTTP会话和Cookie保持等。更多有关信息开源去<a href=\"http://docs.python-requests.org/\">requests的官方介绍网页</a>查看。</p>\n<h3 id=\"requests库解析\"><a href=\"#requests库解析\" class=\"headerlink\" title=\"requests库解析\"></a>requests库解析</h3><p><img src=\"https://cdn.jsdelivr.net/gh/A1andNS/picgo/img/mmexport1585188851577.jpg\" alt=\"图片来源自《Python程序设计基础》\"></p>\n<p> HTTP 协议中 get 功能单纯的从服务器获取数据，服务器中网站数据不可能变化。post 功能可以通过提交表单修改网站的数据（比如注册），网站数据可能变化。</p>\n<p>在HTTP请求后会返回一个<code>response对象</code>，值得一提的是<code>encoding</code>属性很重要，他决定了编码方式。在中文无法显示时就要通过更改response对象的<code>encoding</code>属性来查看中文字符。</p>\n<p><code>post()</code>函数使用起来时，提交的数据要用字典类型来实现。例如<code>requests.post(url,data = &#123;&quot;username&quot;:&quot;admin&quot; , &quot;password&quot;:&quot;123&quot;&#125;)</code></p>\n<p><code>raise_for_status()</code>方法也是一个很好用的东西，开以用来避开状态字200以外的各种意外情况。requests会产生几种常用异常。当遇到网络问题时，如DNS查询失败、拒绝连接等，requests会抛出<code>ConnectionError</code>异常；遇到无效HTTP响应时，requests会抛出<code>HTTPError</code>异常；若请求url超时，就抛出<code>Timeout</code>异常；若请求超过了设定的最大重定向次数，就会抛出一个<code>TooManyRedirects</code>异常。</p>\n<h4 id=\"获取HTML网页\"><a href=\"#获取HTML网页\" class=\"headerlink\" title=\"获取HTML网页\"></a>获取HTML网页</h4><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\">#这是一个获得HTML网页的通用代码</span>\n<span class=\"token keyword\">import</span> requests\n<span class=\"token keyword\">def</span> <span class=\"token function\">getHTMLText</span><span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n        r <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">,</span> timeout<span class=\"token operator\">=</span><span class=\"token number\">30</span><span class=\"token punctuation\">)</span>\n        r<span class=\"token punctuation\">.</span>raise_for_status<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\">#如果状态不是200，引发异常</span>\n        r<span class=\"token punctuation\">.</span>encoding <span class=\"token operator\">=</span>  <span class=\"token string\">'utf-8'</span>    <span class=\"token comment\">#无论原来用什么编码，都改为UFT-8</span>\n        <span class=\"token keyword\">return</span> r<span class=\"token punctuation\">.</span>text\n    <span class=\"token keyword\">except</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">\"\"</span>\nurl <span class=\"token operator\">=</span> <span class=\"token builtin\">input</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"请输入URL:\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>getHTMLText<span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<h3 id=\"requests库主要解析方法\"><a href=\"#requests库主要解析方法\" class=\"headerlink\" title=\"requests库主要解析方法\"></a>requests库主要解析方法</h3><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token comment\">#requests.request(method, url, **kwargs)</span>\n<span class=\"token comment\">#**kwargs为可选项，主要是控制访问的参数</span>\n<span class=\"token comment\">#params:字典或字节序列，作为参数增加到url中</span>\n<span class=\"token comment\">#data:字典或字节序列或文件对象，作为request的内容</span>\n<span class=\"token comment\">#json:JSON格式的数据作为request的内容</span>\n<span class=\"token comment\">#headers: 字典，HTTP定制头</span>\n<span class=\"token comment\">#cookies:字典或cookieJar，request中的cookie</span>\n<span class=\"token comment\">#auth:元组类型，支持HTTP认证功能</span>\n<span class=\"token comment\">#file:字典类型，传输文件</span>\n<span class=\"token comment\">#案例：</span>\nfs <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"file\"</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data.xls'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'rb'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span>\nr<span class=\"token punctuation\">.</span>requests<span class=\"token punctuation\">.</span>request<span class=\"token punctuation\">(</span><span class=\"token string\">'POST'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'http://python123.io/ws'</span><span class=\"token punctuation\">,</span> files<span class=\"token operator\">=</span>fs<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#timeout:设定超时时间，以秒为单位</span>\n<span class=\"token comment\">#proxies：字典类型，设定访问代理服务器，可以增加登陆认证。</span>\n<span class=\"token comment\">#案例：</span>\npxs <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span> <span class=\"token string\">'http'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'http://user:pass@10.10.10.1:1234'</span><span class=\"token punctuation\">,</span>\n      <span class=\"token string\">'https'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'https://10.10.10.1:4321'</span><span class=\"token punctuation\">&#125;</span>\nr <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>request<span class=\"token punctuation\">(</span><span class=\"token string\">'GET'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'http://www.baidu.com'</span><span class=\"token punctuation\">,</span> proxies<span class=\"token operator\">=</span>pxs<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#allow_redirects: True/False,默认为True，重定向开关</span>\n<span class=\"token comment\">#stream: True/False,默认为True，获取内容立即下载开关</span>\n<span class=\"token comment\">#verify: True/False,默认为True，认证SSL证书开关</span>\n<span class=\"token comment\">#cert: 本地SSL证书路径</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<h2 id=\"beautifulsoup4库的使用\"><a href=\"#beautifulsoup4库的使用\" class=\"headerlink\" title=\"beautifulsoup4库的使用\"></a>beautifulsoup4库的使用</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>beautifulsoup4库时一个解析和处理HTML和XML的第三方库。</p></blockquote>\n<h3 id=\"beautifulsoup4库概述\"><a href=\"#beautifulsoup4库概述\" class=\"headerlink\" title=\"beautifulsoup4库概述\"></a>beautifulsoup4库概述</h3><p>使用<code>requests</code>库获取到HTML页面并将其转换为字符串后，需要进一步解析HTML页面的格式，提取有用的信息，这就需要处理HTML和XML的函数库。</p>\n<p><code>beautifulsoup4</code>库，也被称为<code>bs4</code>库，用来解析和处理HTML和XML。但是要注意一点，他不是<code>BeautifulSoup</code>类。它最大的优点是能够根据HTML和XML语法构建解析树，进而高效解析其中的内容。</p>\n<p><code>beautifulsoup4</code>库是采用面向对象思想实现的，他把每一个网页作为一个对象，通过<a>.<b>的方式来调用对象属性，或者使用<a>.<b>()来调用方法。所以再需要进行引用时可以使用from-import方式直接引用<code>BeautifulSoup</code>类。具体的介绍可以去访问<a href=\"http://www.crummy.com/software/BeautifulSoup/bs4/\">这个第三方库的主页</a></p>\n<h3 id=\"beautifulsoup4库解析\"><a href=\"#beautifulsoup4库解析\" class=\"headerlink\" title=\"beautifulsoup4库解析\"></a>beautifulsoup4库解析</h3><p><img src=\"https://cdn.jsdelivr.net/gh/A1andNS/picgo/img/1.jpg\" alt=\"图片来源自《Python程序设计基础》\"></p>\n<p>在<code>bs4</code>里最主要的就是<code>BeautifulSoup</code>类，每个实例化的对象都相当于一个页面。采用<code>from-import</code>导入库中的<code>BeautifulSoup</code>类后使用<code>BeautifulSoup()</code>就可以创建一个<code>BeautifulSoup</code>对象了。如下图：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/A1andNS/picgo/img/20200326162331.png\" alt=\"创建一个BeautifulSoup对象\"></p>\n<p><code>BeautifulSoup</code>对象时一个树形结构，包含HTML页面中的每一个Tag元素，HTML中的每一个Tag都成为了<code>BeautifulSoup</code>对象的一个属性，可以使用面向对象方法来获取属性。属性名就是Tag名。而且HTML里面的每一个标签也是一个Tag对象。并且可以创建一个<code>Tag</code>对象，如下图所示：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/A1andNS/picgo/img/20200326163700.png\" alt=\"BeautifulSoup对象属性和创建Tag对象\"></p>\n<p><code>Tag对象</code>的属性就是每一个Tag所拥有的部分，像尖括号内标签的名字为<code>name</code>、尖括号内的其他项为<code>attrs</code>、尖括号之间的为<code>string</code>。如下图所示：</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/A1andNS/picgo/img/20200326165711.png\" alt=\"对Tag对象的一些查看\"></p>\n<p>直接使用<code>soup.a</code>是只能返回第一个a标签的，而由于HTML语法的嵌套，所以一个标签里可能还有别的标签，这里有一点要注意，string属性的返回值要遵循如下的原则：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><ol>\n<li>如果标签内部没有其他标签，string属性返回其中的内容。</li>\n<li>如果标签内部还有其他的标签，但是只有一个标签，string属性返回最里面标签的内容。</li>\n<li>如果标签内部有超过1层嵌套的标签，string属性返回None。</li>\n</ol></blockquote>\n<p>如果想要列出标签对应的所有内容或者需要找非第一个标签，就要用到BeautifulSoup的find()和fing_all()方法来实现。find()方法返回找到的第一个结果，find_all()方法返回找到的所有结果。</p>\n<p><code>BeautifulSoup.find_all(name, attrs, recursive, string, limit)</code></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/A1andNS/picgo/img/20200326173528.png\" alt=\"find方法使用\"></p>\n<p>要把这些库结合运用起来，编写一个爬虫程序，就可以爬取内容或者获取想要的信息，而且可能会更加高效。</p>\n","text":"今天来学习一下Python语言如何进行网络爬虫和自动化。 Python语言提供了很多可供使用的第三方库，包括urllib、urllib2、urllib3、wget、scrapy、requests等。这些库都会是好帮手。最经常看到的就是requests库了。 网络爬虫应用一般分为两...","link":"","photos":[],"count_time":{"symbolsCount":"3.4k","symbolsTime":"3 mins."},"categories":[{"name":"Python学习","slug":"Python学习","count":19,"path":"api/categories/Python学习.json"}],"tags":[{"name":"WEB","slug":"WEB","count":39,"path":"api/tags/WEB.json"},{"name":"Python","slug":"Python","count":23,"path":"api/tags/Python.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#requests%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8\"><span class=\"toc-text\">requests库的使用</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#requests%E5%BA%93%E7%AE%80%E4%BB%8B\"><span class=\"toc-text\">requests库简介</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#requests%E5%BA%93%E8%A7%A3%E6%9E%90\"><span class=\"toc-text\">requests库解析</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%8E%B7%E5%8F%96HTML%E7%BD%91%E9%A1%B5\"><span class=\"toc-text\">获取HTML网页</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#requests%E5%BA%93%E4%B8%BB%E8%A6%81%E8%A7%A3%E6%9E%90%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">requests库主要解析方法</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#beautifulsoup4%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8\"><span class=\"toc-text\">beautifulsoup4库的使用</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#beautifulsoup4%E5%BA%93%E6%A6%82%E8%BF%B0\"><span class=\"toc-text\">beautifulsoup4库概述</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#beautifulsoup4%E5%BA%93%E8%A7%A3%E6%9E%90\"><span class=\"toc-text\">beautifulsoup4库解析</span></a></li></ol></li></ol>","author":{"name":"A1andNS","slug":"blog-author","avatar":"/svg/head.png","link":"/","description":"爱你所爱，行你所行，听从你心，无问西东","socials":{"github":"https://github.com/A1andNS","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"中国大学排名爬虫","uid":"143867234a6f40c419fe07b5ab60f166","slug":"中国大学排名爬虫","date":"2020-03-26T11:26:48.000Z","updated":"2020-04-13T00:47:14.000Z","comments":true,"path":"api/articles/中国大学排名爬虫.json","keywords":"A1andNS","cover":"https://cdn.jsdelivr.net/gh/A1andNS/picgo/img/20200323233608.png","text":"今天学了网络爬虫相关的知识，就接着来学习一下实例。 爬虫构建的3个步骤： 从网络上获取网页的内容 分析网页内容并提取有用数据到恰当的数据结构中 利用数据结构展示或进一步处理数据。 要想爬取排名，就要知道网页的源代码结构，这样才能爬取到有效信息。 可以看出每一个大学的信息都被封装在...","link":"","photos":[],"count_time":{"symbolsCount":"4k","symbolsTime":"4 mins."},"categories":[{"name":"Python学习","slug":"Python学习","count":19,"path":"api/categories/Python学习.json"}],"tags":[{"name":"WEB","slug":"WEB","count":39,"path":"api/tags/WEB.json"},{"name":"Python","slug":"Python","count":23,"path":"api/tags/Python.json"}],"author":{"name":"A1andNS","slug":"blog-author","avatar":"/svg/head.png","link":"/","description":"爱你所爱，行你所行，听从你心，无问西东","socials":{"github":"https://github.com/A1andNS","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"乒乓球参数雷达图","uid":"8ab514a135a5a3eda795763cee6202a4","slug":"乒乓球参数雷达图","date":"2020-03-26T01:12:55.000Z","updated":"2020-04-13T00:46:16.000Z","comments":true,"path":"api/articles/乒乓球参数雷达图.json","keywords":"A1andNS","cover":"https://cdn.jsdelivr.net/gh/A1andNS/picgo/img/20200323233608.png","text":"今天写一个乒乓球和参数雷达图，这个和昨天的程序原理和流程基本是一样的们就是更换了data内容和angles内容。 下面看代码： 运行环境 系统：Windows 10 version 1909 Python：Python 3.7.4 第三方库: matplotlib 、numpy ...","link":"","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"Python学习","slug":"Python学习","count":19,"path":"api/categories/Python学习.json"}],"tags":[{"name":"Python","slug":"Python","count":23,"path":"api/tags/Python.json"}],"author":{"name":"A1andNS","slug":"blog-author","avatar":"/svg/head.png","link":"/","description":"爱你所爱，行你所行，听从你心，无问西东","socials":{"github":"https://github.com/A1andNS","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}